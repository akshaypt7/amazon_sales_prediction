{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_01.04_Using_entity_embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaypt7/amazon_sales_prediction/blob/main/project_01_04_Using_entity_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJzX6jTIR2pq"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In this part, we will use the embeddings created in the previous notebook and will train both random forest and neural network with the entity embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Bkug-DSwBU"
      },
      "source": [
        "#### Representation of Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaxhEW0dSFth"
      },
      "source": [
        "This is how the embeddings are represneted for each category in the dataframe.\n",
        "\n",
        "\n",
        "Embedding order = [asin_embedding, hours_embedding, dayofweek_embedding,\n",
        "                  month_embedding, day_embedding, week_embedding]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "{0: 0, 3: 1, 9: 2, 6: 3, 8: 4, 7: 5}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "columns =   ['Asin', 'Item Promo Discount', 'price', 'hour', 'Invoice Amount',\n",
        "       'Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
        "       'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start',\n",
        "       'Is_year_end', 'Is_year_start', 'Elapsed']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaD1ITGwS2cP"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOf7-glAqKQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa36f144-469b-4e47-96f4-d067d20929df"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 267 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMc_wTu9apCs"
      },
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "# from kaggle import api\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# from dtreeviz.trees import *\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_columns = 8\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26gA0_jd4-C"
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dense, Flatten, Dropout, Input, Embedding, Reshape\n",
        "from keras.layers import concatenate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrSVr08wZYGu"
      },
      "source": [
        "infile = open('/content/gdrive/MyDrive/bluebook/df_main.pkl','rb')\n",
        "df_main = pickle.load(infile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIW-uPJ5ahf5"
      },
      "source": [
        "df_main = add_datepart(df_main,'date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM10uhszhO_H"
      },
      "source": [
        "cat = ['Asin',\n",
        " 'Is_month_end',\n",
        " 'Is_month_start',\n",
        " 'Is_quarter_end',\n",
        " 'Is_quarter_start',\n",
        " 'Is_year_end',\n",
        " 'Is_year_start',\n",
        " 'hour','Month','Week', 'Day','Dayofweek','Dayofyear']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXYHFhuLjIE5"
      },
      "source": [
        "enc = OrdinalEncoder()\n",
        "enc.fit(df_main[cat])\n",
        "df_main[cat]= enc.transform(df_main[cat])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5dnKBUL2RBl"
      },
      "source": [
        "condition = (df_main.Year < 2020) | (df_main.Month < 8)\n",
        "train_idx = np.where(condition)[0]\n",
        "valid_idx = np.where(~condition)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xBYrnvNErMh"
      },
      "source": [
        "X =df_main.drop(['Quantity'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3lBx8b-2X_h"
      },
      "source": [
        "X_train = df_main.drop(['Quantity'],axis=1).iloc[train_idx]\n",
        "y_train = df_main['Quantity'].iloc[train_idx]\n",
        "\n",
        "X_valid = df_main.drop(['Quantity'],axis=1).iloc[valid_idx]\n",
        "y_valid = df_main['Quantity'].iloc[valid_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mHj7Ux0Culm"
      },
      "source": [
        "saved_embeddings_fname = '/content/gdrive/MyDrive/bluebook/embeddings.pickle'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "117RoeyDTDFv"
      },
      "source": [
        "### Loading the Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SshxsQBvTVOs"
      },
      "source": [
        "#### We are replacing the columns with thier respective entity embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLf5Q39Ckk7"
      },
      "source": [
        "def embed_features(X, saved_embeddings_fname):\n",
        "    f_embeddings = open(saved_embeddings_fname, \"rb\")\n",
        "    embeddings = pickle.load(f_embeddings)\n",
        "\n",
        "    index_embedding_mapping = {0: 0, 3: 1, 9: 2, 6: 3, 8: 4, 7: 5}\n",
        "    X_embedded = []\n",
        "\n",
        "    (num_records, num_features) = X.shape\n",
        "    for record in X:\n",
        "        embedded_features = []\n",
        "        for i, feat in enumerate(record):\n",
        "            feat = int(feat)\n",
        "            if i not in index_embedding_mapping.keys():\n",
        "                embedded_features += [feat]\n",
        "            else:\n",
        "                embedding_index = index_embedding_mapping[i]\n",
        "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
        "\n",
        "        X_embedded.append(embedded_features)\n",
        "\n",
        "    return np.array(X_embedded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeSEWujEdvm"
      },
      "source": [
        "X_emb = embed_features(X.values,saved_embeddings_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NVxjVSTTfNi"
      },
      "source": [
        "#### Using the same Valid and Train set we used earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WPjwqVvHAbf"
      },
      "source": [
        "X_train = list(itemgetter(*train_idx)(X_emb)) \n",
        "X_valid = list(itemgetter(*valid_idx)(X_emb)) \n",
        "\n",
        "# or we can use list comprehension too for ex, test = [X_emb[i] for i in train_idx ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuNywq7-EhEr"
      },
      "source": [
        "\n",
        "y_train = df_main['Quantity'].iloc[train_idx]\n",
        "\n",
        "y_valid = df_main['Quantity'].iloc[valid_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9iWyAEPzZI"
      },
      "source": [
        "Note : We have created the train and test set from the X_embeddings. since X_embeddings is a list we use either list comprehension or list(itemgetter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLGiPhR5G3_D"
      },
      "source": [
        "refer - https://stackoverflow.com/questions/25431850/passing-a-list-of-indices-to-another-list-in-python-correct-syntax"
      ]
    }
  ]
}