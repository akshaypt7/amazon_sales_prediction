{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_01.05_visualizing_embedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0X59pnDOb3yR8ipeVUtqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaypt7/amazon_sales_prediction/blob/main/project_01_05_visualizing_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOf7-glAqKQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a787623-ada7-4356-cc8a-70f0a5864abb"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 70.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 332 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMc_wTu9apCs"
      },
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "# from kaggle import api\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# from dtreeviz.trees import *\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "\n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.max_columns = 8"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26gA0_jd4-C"
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dense, Flatten, Dropout, Input, Embedding, Reshape\n",
        "from keras.layers import concatenate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1CeqUoznKkg"
      },
      "source": [
        "What we could do here is visualize the entity embedding, we might not able to gather anything huge, but somethings like Asin_embedding and hour embedding might give us some info. And also this is something I can use somewhere else too.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thTaYABDo3ew"
      },
      "source": [
        "The beauty of embedding is it is so beautiful, some numbers which starts as an assumption or random creates a meaning btw the numbers is awesome, which means it might be able to show relations that maybe we miss. \n",
        "\n",
        "This is definitely that can be beautiful to see how its going to happen, even though I am a bit lacking in clarity on how to proceed with doing this. \n",
        "\n",
        "The reason is whenever I looked at certain codes, everything seems confusing to me. but that is the fun of this from confusion of where to work we focused of visualizing the embeddings, and from there it might be again a confusing road but i think that is okay, rather than trying to visualize lets break down and see what is going to happen. \n",
        "\n",
        "We can put out a theory which can help us on how to proceed.\n",
        "\n",
        "\n",
        "the theory is , we take one embedding like asin_embedding this will have a rows of list of numbers, say 10 columns of list, with as many rows as the number of, but we have given embeddings not the same size of unique asins?, should we give the size of the same , but i didnt observed that anywhere else, but if we have not given the same size, what will they represent, the chance is they would represent, maybe like groups of asin, but then how would you know which asins are which. but i think one of the input we have given is unique asin number, so there would be some data which represents that, and we can use that.\n",
        "\n",
        "\n",
        "\n",
        "Using Diffused thinking, which I should do more often which gives more clarity and a break to our mind, what i found out is two things\n",
        "\n",
        "1) that we will have unqiue number of list(embeddings), each embeddings is a list of numbers and this number of embeddings = number of unique asins. And then we use PCA analysis to understand what it is. exciting news is we will also learn about PCA.\n",
        "\n",
        "2) we can try this embedding in fastai version of the learner, when we create our own module, i think it wont be that confusing, and it is simple(not easy), where we create a class from module, and it that we pass in the embedding details and also at the end, we can get this by calling something like learner.embs etc..\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "about learning diffused\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "One thing we can try later as well is using embeddings of fastai, use the collab chapter one, there there is only two variables, they have considered it both cat variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slbGkR51mymi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DcuzOOw1FpW"
      },
      "source": [
        "#### Lets look at the embeddings in detail and understand its attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SuVDLcj1LFJ"
      },
      "source": [
        "saved_embeddings_fname = '/content/gdrive/MyDrive/bluebook/embeddings.pickle'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyyUwWjg10Al"
      },
      "source": [
        "def embed_features(X, saved_embeddings_fname):\n",
        "    f_embeddings = open(saved_embeddings_fname, \"rb\")\n",
        "    embeddings = pickle.load(f_embeddings)\n",
        "\n",
        "    index_embedding_mapping = {0: 0, 3: 1, 9: 2, 6: 3, 8: 4, 7: 5}\n",
        "    X_embedded = []\n",
        "\n",
        "    (num_records, num_features) = X.shape\n",
        "    for record in X: \n",
        "        embedded_features = []\n",
        "        for i, feat in enumerate(record):\n",
        "            feat = int(feat)\n",
        "            if i not in index_embedding_mapping.keys():\n",
        "                embedded_features += [feat]\n",
        "            else:\n",
        "                embedding_index = index_embedding_mapping[i]\n",
        "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
        "\n",
        "        X_embedded.append(embedded_features)\n",
        "\n",
        "    return np.array(X_embedded)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "PjAXe4Fy12oc",
        "outputId": "f1e05d0d-e52e-4a5e-bfd4-e95154c1909f"
      },
      "source": [
        "X_emb = embed_features(X.values,saved_embeddings_fname)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4fc6e1481126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaved_embeddings_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0P_FQg615AH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}